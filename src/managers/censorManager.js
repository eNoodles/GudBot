const { Message, TextChannel, Webhook, Collection } = require('discord.js');
const { blacklist, whitelist } = require('../database/dbObjects');
const { ids, prependFakeReply, findLastSpaceIndex, getGuildUploadLimit, logUnless } = require('../utils');
const { addToMessageGroups } = require('./spamManager');

let blacklist_regexp = new RegExp('', 'ig');

/**
 * K: Snowflake representing channel id
 * V: gudbot's webhook for that channel
 * @type {Collection<string,Webhook>}
 */
const webhooks_cache = new Collection();
/**
 * K: Snowflake representing message id
 * V: Snowflake representing original message author's id
 * @type {Collection<string,string>}
 */
const censored_authors_cache = new Collection();

/**
 * Caches message author id by corresponding censored message id. Used for looking up author of censored message in "Delete and jail" command.
 * @param {string} message_id ID of censored message sent by webhook
 * @param {string} author_id ID of author who sent the original uncensored message
 */
 function cacheAuthorId(message_id, author_id) {
    //message id is the key because there will be no way on knowing who the original author was later
    censored_authors_cache.set(message_id, author_id);
    //keep cache under 10000 elements
    if (censored_authors_cache.size > 10000) {
        //get first 100 keys
        const keys = censored_authors_cache.firstKey(100);
        //delete those elements
        keys.forEach(key => censored_authors_cache.delete(key));
    }
}

const confusables = [
    //A
    ['a', '@', 'É‘', 'Î±', 'Ğ°', 'âº', 'ğš', 'ï½', 'áº¡', 'Ä…', 'Ã¤', 'Ã ', 'Ã¡', 'áª', 'á—…', 'ê“®', 'ğŠ ', 'ğŸ‡¦', 'Ğ´', '4', 'ğŸ…°ï¸', '4ï¸âƒ£', 'ğ”', 'ğ”„', 'ğ–†', 'ğ•¬', 'à¸„', 'ğ“ª', 'ğ“', 'ğ’¶', 'ğ’œ', 'ğ•’', 'ğ”¸', 'á´€', 'ğŸ„°', 'âˆ€', 'É', 'É’', 
    'â‚', 'áµƒ', 'á´¬', 'â“', 'ğ€', 'ğ—®', 'ğ—”', 'ğ˜¢', 'ğ˜ˆ', 'ğ™–', 'ğ˜¼', 'ğšŠ', 'ğ™°', 'ÇŸ', 'á—', 'Ã¥', 'â‚³', 'å‚', 'ï¾‘', 'Î›', 'Èº', 'á—©', 'Ãƒ', 'Î¬', 'Âª', 'Ã¢', 'Ä', 'Äƒ', 'Ç', 'È', 'Èƒ', 'È§', 'á¸', 'áºš', 'áº¥', 'áº§', 'áº©', 'Ç»', 'áº¯', 
    'áº±', 'áº³', 'áºµ', 'Ç¡', 'áº­', 'áº·', 'áº£', 'â’œ', 'ğ’‚', 'ğ–º'],
    //B
    ['b', 'Æ„', 'á', 'á‘²', 'á–¯', 'ğ›', 'Î’', 'Ğ’', 'á´', 'á—·', 'â„¬', 'ê“', 'ê´', 'ğŠ‚', 'ï¼¢', 'ğŸ‡§', 'ÑŠ', 'ÑŒ', 'Ğ±', '8', 'ğŸ…±ï¸', '8ï¸âƒ£', 'ğ”Ÿ', 'ğ”…', 'ğ–‡', 'ğ•­', 'ğ“«', 'ğ“‘', 'ğ’·', 'ğµ', 'ğ•“', 'ğ”¹', 'Ê™', 'ğŸ„±', 'á™ ', 'áµ‡', 'á´®', 'â“‘', 
    'à¹’', 'á‚¦', 'ğ', 'ğ—¯', 'ğ—•', 'ğ˜£', 'ğ˜‰', 'ğ™—', 'ğ˜½', 'ğš‹', 'ğ™±', 'É®', 'á°', 'áƒª', 'à¹–', 'ÃŸ', 'à¸¿', 'ä¹ƒ', 'Ò', 'á¸ƒ', 'á¸…', 'á¸‡', 'â’', 'ğ‘', 'ğ’ƒ', 'ğ–»'],
    //C
    ['c', 'Ï²', 'á´„', 'â…½', 'â²¥', 'ê®¯', 'ğ½', 'ğœ', 'ï½ƒ', 'Ñ', 'Æˆ', 'Ä‹', 'â„‚', 'â„­', 'ê“š', 'ğŠ¢', 'ğŸŒ', 'ğŸ‡¨', 'Â©ï¸', 'ğ” ', 'ğ–ˆ', 'ğ•®', 'ğ•”', 'ğ“¬', 'ğ“’', 'ğ’¸', 'ğ’', 'ğŸ„²', 'ğŸ…²', 'Æ†', 'á¶œ', 'â“’', 'ğ‚', 'ğ—°', 'ğ—–', 'ğ˜¤', 'ğ˜Š', 'ğ™˜', 'ğ˜¾', 
    'ğšŒ', 'ğ™²', 'Â¢', 'á„ƒ', 'Ã‡', 'â‚µ', 'åŒš', 'Ïš', 'á‘•', 'á‘¢', 'Ä†', 'ÄŒ', 'á¸‰', 'Ä‰', 'â’', 'ğ‘', 'ğ’„', 'ğ–¼', 'ğ˜¤'],
    //D
    ['d', 'á§', 'á‘¯', 'â…†', 'â…¾', 'ê“’', 'ğ', 'Ô', 'É—', 'á ', 'á—', 'á—ª', 'â……', 'ê““', 'ğŸ‡©', 'ğ”¡', 'ğ”‡', 'ğ–‰', 'ğ•¯', 'ï½„', 'âˆ‚', 'ğ“­', 'ğ““', 'ğ’¹', 'ğ’Ÿ', 'ğ••', 'ğ”»', 'ğŸ„³', 'ğŸ…³', 'á—¡', 'áµˆ', 'á´°', 'â““', 'à¹”', 'Ôƒ', 'ğƒ', 'ğ—±', 'ğ——', 
    'ğ˜¥', 'ğ˜‹', 'ğ™™', 'ğ˜¿', 'ğš', 'ğ™³', 'É–', 'á´', 'à»“', 'Ã', 'Ä', 'ã®', 'á•²', 'Ä', 'á¸‹', 'á¸', 'á¸', 'á¸‘', 'á¸“', 'â’Ÿ', 'ğ‘‘', 'ğ’…', 'ğ–½'],
    //E
    ['e', 'Ò½', 'â„®', 'â„¯', 'â…‡', 'ê¬²', 'ğ', 'ï½…', 'Ğµ', 'áº¹', 'Ä—', 'Ã©', 'Ã¨', 'Î•', 'á¬', 'â„°', 'â‹¿', 'â´¹', 'ê“°', 'ğŠ†', 'ğŸ‡ª', 'Ñ', 'Ñ‘', '3', '3ï¸âƒ£', 'ğ”¢', 'ğ”ˆ', 'ğ–Š', 'ğ•°', 'ğ“®', 'ğ“”', 'ğ‘’', 'ğ¸', 'ğ•–', 'ğ”¼', 'á´‡', 'ğŸ„´', 'ğŸ…´', 'Ç', 
    'É˜', 'â‚‘', 'áµ‰', 'á´±', 'â“”', 'Ñ”', 'ğ„', 'ğ—²', 'ä¹‡', 'ğ—˜', 'ğ˜¦', 'ğ˜Œ', 'ğ™š', 'ğ™€', 'Î­', 'ğš', 'ğ™´', 'É›', 'á‹', 'Ä“', 'Ãª', 'Â£', 'É†', 'á˜¿', 'á—±', 'á—´', 'â‚¬', 'ğ’†', 'áº¿', 'á»', 'á»ƒ', 'á»…', 'Ã«', 'á¸•', 'á¸—', 'Ä•', 'Ä™', 'Ä›', 'È…', 
    'È‡', 'È©', 'á¸', 'á¸™', 'á¸›', 'á»‡', 'áº»', 'áº½', 'â’ ', 'ğ–¾'],
    //F
    ['f', 'Å¿', 'Ö„', 'áº', 'ê™', 'ê¬µ', 'ğŸ', 'Ïœ', 'á–´', 'â„±', 'ê“', 'ğŠ‡', 'ğŸ‡«', 'ğ”£', 'ğ”‰', 'ğ–‹', 'ğ•±', 'ğ•—', 'ğ”½', 'ğ“¯', 'ğ“•', 'ğ’»', 'ğ¹', 'ï½†', 'êœ°', 'ğŸ„µ', 'ğŸ…µ', 'â„²', 'ÉŸ', 'êŸ»', 'á¸', 'á¶ ', 'â“•', 'Å¦', 'ğ…', 'ğ—³', 'ğ—™', 'ğ˜§', 'ğ˜', 
    'ğ™›', 'ğ™', 'ğš', 'ğ™µ', 'Ê„', 'Æ’', 'â‚£', 'åƒ', 'Ò“', 'ğ’‡', 'á¸Ÿ', 'â’¡', 'ğ‘“', 'ğ–¿'],
    //G
    ['g', 'Æ', 'É¡', 'Ö', 'á¶ƒ', 'â„Š', 'ğ ', 'ğ‘”', 'ğ’ˆ', 'ğ“°', 'ğ”¤', 'ğ•˜', 'ğ–Œ', 'ğ—€', 'ğ—´', 'ğ˜¨', 'ğ™œ', 'ğš', 'ï½‡', 'Ä¡', 'ÔŒ', 'á€', 'á³', 'ê“–', 'ğ†', 'ğº', 'ğ‘®', 'ğ’¢', 'ğ“–', 'ğ”Š', 'ğ”¾', 'ğ•²', 'ğ–¦', 'ğ—š', 'ğ˜', 'ğ™‚', 'ğ™¶', 'ğŸ‡¬', 
    '6', '9', '6ï¸âƒ£', '9ï¸âƒ£', 'á¶', 'É¢', 'ğŸ„¶', 'ğŸ…¶', 'â…', 'É“', 'áµ', 'á´³', 'á˜œ', 'â“–', 'ï»®', 'É ', 'àº‡', 'â‚²', 'Ä£', 'Ä', 'Ç¤', 'Ä', 'Ç§', 'Çµ', 'á¸¡', 'â’¢'],
    //H
    ['h', 'Ò»', 'Õ°', 'á‚', 'â„', 'ğ¡', 'ğ’‰', 'ğ’½', 'ğ“±', 'ğ”¥', 'ğ•™', 'ğ–', 'ğ—', 'ğ—µ', 'ğ˜©', 'ğ™', 'ğš‘', 'ï½ˆ', 'Î—', 'á»', 'á•¼', 'â„‹', 'â„Œ', 'â„', 'â²', 'ê“§', 'ğ‹', 'ğ‡', 'ğ»', 'ğ‘¯', 'ğ“—', 'ğ•³', 'ğ–§', 'ğ—›', 'ğ˜', 'ğ™ƒ', 'ğ™·', 
    'ğš®', 'ğ›¨', 'ğœ¢', 'ğœ', 'ğ–', 'ğŸ‡­', 'Ğ½', 'Êœ', 'ğŸ„·', 'ğŸ…·', 'É¥', 'ã‚“', 'â‚•', 'Ê°', 'á´´', 'â“—', 'Ñ’', 'Ô‹', 'É¦', 'É§', 'Î‰', 'â±§', 'å„', 'Ç¶', 'Ä¤', 'Ä§', 'ÈŸ', 'á¸£', 'á¸¥', 'á¸§', 'á¸©', 'á¸«', 'áº–', 'â’£'],
    //I
    ['i', 'Ä±', 'É©', 'Éª', 'Î¹', 'Ñ–', 'Ó', 'á¥', 'â„¹', 'â…ˆ', 'â…°', 'â³', 'ê™‡', '\\|', 'Ç€', '×€', 'ßŠ', 'á›', 'â„', 'â„‘', 'â„“', 'âˆ£', 'â²’', 'âµ', 'ê“²', 'ğŠŠ', 'ğŒ‰', 'Ã­', 'Ã¯', 'ğŸ‡®', '1', '1ï¸âƒ£', 'ğ”¦', 'ğ–', 'ğ•´', 'ï½‰', 'ğ“²', 'ğ“˜', 'ğ’¾', 
    'ğ¼', 'ğ•š', 'ğ•€', 'ğŸ„¸', 'ğŸ…¸', 'áµ¢', 'â±', 'á´µ', 'â“˜', 'à¹€', 'ğ¢', 'ğˆ', 'ğ—¶', 'ğ—œ', 'ğ˜ª', 'ğ˜', 'ğ™', 'ğ™„', 'ï¾‰', 'ğš’', 'ğ™¸', 'É¨', 'ÃŒ', 'Å‚', 'ä¸¨', 'Ä¯', 'á“°', 'Ã®', 'á¸¯', 'Ä©', 'Ä«', 'Ä­', 'Ç', 'È‰', 'È‹', 'á¸­', 'á»‰', 'á»‹', 'â’¤', 
    'ğ‘–', 'ğ’Š', 'ğ—‚'],
    //J
    ['j', 'Ï³', 'Ñ˜', 'â…‰', 'ğ£', 'ğ‘—', 'ğ’‹', 'ğ’¿', 'ğ“³', 'ğ”§', 'ğ•›', 'ğ–', 'ğ—ƒ', 'ğ—·', 'ğ˜«', 'ğ™Ÿ', 'ğš“', 'ï½Š', 'á«', 'á’', 'ê“™', 'ê²', 'ğ‰', 'ğ½', 'ğ‘±', 'ğ’¥', 'ğ“™', 'ğ”', 'ğ•', 'ğ•µ', 'ğ–©', 'ğ—', 'ğ˜‘', 'ğ™…', 'ğ™¹', 'ğŸ‡¯', 'Ä´', 'á´Š', 'ğŸ„¹', 'ğŸ…¹', 
    'É¾', 'á‚±', 'ê', 'â±¼', 'Ê²', 'á´¶', 'â“™', '×Ÿ', 'á', 'à¸§', '× ', 'ï¾Œ', 'Ù„', 'á’š', 'á’', 'Ú¶', 'Ç°', 'â’¥'],
    //K
    ['k', 'ğ¤', 'ğ‘˜', 'ğ’Œ', 'ğ“€', 'ğ“´', 'ğ•œ', 'ğ—„', 'ğ—¸', 'ğ˜¬', 'ğ™ ', 'ğš”', 'Îš', 'á¦', 'á›•', 'â²”', 'ê“—', 'ï¼«', 'ğŸ‡°', 'Ğº', 'ğ”¨', 'ğ”', 'ğ–', 'ğ•¶', 'ğ“š', 'ğ’¦', 'ğ•‚', 'á´‹', 'ğŸ„º', 'ğŸ…º', 'â‹Š', 'Ê', 'â‚–', 'áµ', 'á´·', 'â“š', 'Æ™', 'ğŠ', 
    'ğ—', 'ğ˜’', 'ğ™†', 'ğ™º', 'Ó„', 'â‚­', 'Òœ', 'ÒŸ', 'Ò ', 'á–½á¸', 'ĞŒ', 'Ä·', 'Ç©', 'á¸±', 'á¸³', 'á¸µ', 'â’¦'],
    //L
    ['l', 'ßŠ', 'â…¼', 'á', 'á’ª', 'â„’', 'â³', 'ê“¡', 'ğ›', 'á¸·', 'ğŸ‡±', 'ğ”©', 'ğ”', 'ğ–‘', 'ğ•·', 'ğ“›', 'ğ•', 'ğ“µ', 'ğ“', 'ğ¿', 'ğ•ƒ', 'ï½Œ', 'ÊŸ', 'ğŸ„»', 'ğŸ…»', 'Ë¥', 'â…ƒ', 'â‚—', 'Ë¡', 'á´¸', 'â“›', 'É­', 'Ê…', 'ğ¥', 'ğ‹', 'ğ—¹', 'ğ—Ÿ', 'ğ˜­', 'ğ˜“', 
    '1', '1ï¸âƒ£', 'ğ™¡', 'ğ™‡', 'ğš•', 'ğ™»', 'á„‚', 'â± ', 'ã„¥', 'êˆ', 'Ä¹', 'Ä»', 'Ä¾', 'Å€', 'á¸¹', 'á¸»', 'á¸½', 'â’§', 'ğ‘™', 'ğ’', 'ğ—…'],
    //M
    ['m', 'â…¿', 'Îœ', 'Ïº', 'á·', 'á—°', 'á›–', 'â„³', 'â²˜', 'ê“Ÿ', 'ğŠ°', 'ğŒ‘', 'ğŒ', 'ğ‘€', 'ğ‘´', 'ğ“œ', 'ğ”', 'ğ•„', 'ğ•¸', 'ğ–¬', 'ğ— ', 'ğ˜”', 'ğ™ˆ', 'ğ™¼', 'ğš³', 'ğ›­', 'ğœ§', 'ğ¡', 'ğŸ‡²', 'Ğ¼', 'â“‚ï¸', 'â“‚', 'ğ”ª', 'ğ–’', 'ğ“‚', 
    'ğ“¶', 'ğ•', 'ï½', 'á´', 'ğŸ„¼', 'ğŸ…¼', 'â‚˜', 'áµ', 'á´¹', 'à¹“', 'É±', 'ğ¦', 'ğ—º', 'ğ˜®', 'ğ™¢', 'ğš–', 'Ê', 'ï¾¶', 'çˆª', 'á˜»', 'â‚¥', 'á¸¿', 'á¹', 'á¹ƒ', 'â’¨', 'ğ‘š', 'ğ’', 'ğ—†'],
    //N
    ['n', 'Õ¸', 'Õ¼', 'ğ§', 'ğ‘›', 'ğ’', 'ğ“ƒ', 'ğ“·', 'ğ”«', 'ğ•Ÿ', 'ğ–“', 'ğ—‡', 'ğ—»', 'ğ˜¯', 'ğ™£', 'ğš—', 'Î', 'â„•', 'â²š', 'ê“ ', 'ï¼®', 'ğŸ‡³', 'Ğ¿', 'Ğ»', 'Ğ¸', 'ğ”‘', 'ğ•¹', 'ğ', 'ğ“', 'ğ’©', 'É´', 'ğŸ„½', 'ğŸ…½', 'Í¶', 'á´', 'â‚™', 'â¿', 
    'á´º', 'â“', 'à¸ ', 'É³', 'ğ—¡', 'ğ˜•', 'ğ™‰', 'ğ™½', 'á', 'Å‹', 'àº–', 'Ã±', 'â‚¦', 'å‡ ', 'Õ²', 'á‘', 'á˜‰', 'Å‡', 'á¶°', 'Å„', 'Å†', 'Å‰', 'Ç¹', 'á¹…', 'á¹‡', 'á¹‰', 'á¹‹', 'â’©', 'ğ”¶', 'ğ–'],
    //O
    ['o', 'Ïƒ', '×¡', 'à¥¦', 'à©¦', 'à«¦', 'à¯¦', 'à±¦', 'à³¦', 'à´ ', 'àµ¦', 'à¹', 'à»', 'á€', 'á€', 'áƒ¿', 'ß€', 'à§¦', 'à¬ ', 'à­¦', 'á‹', 'â²', 'âµ”', 'ã€‡', 'ê“³', 'ğŠ’', 'ğŠ«', 'ğ„', 'ğ“‚', 'Ğ¾', 'Î¿', 'Ö…', 'È¯', 
    'á»', 'á»', 'Æ¡', 'Ã³', 'Ã²', 'Ã¶', 'ğŸ‡´', '0', 'ğŸ…¾ï¸', 'â­•', '0ï¸âƒ£', 'ğ”¬', 'ğ”’', 'ğ–”', 'ğ•º', 'à¶§', 'ï½', 'ğ“¸', 'ğ“', 'ğ‘œ', 'ğ’ª', 'ğ• ', 'ğ•†', 'á´', 'ğŸ„¾', 'â‚’', 'áµ’', 'á´¼', 'â“', 'à¹', 'ğ¨', 'ğ', 'ğ—¼', 'ğ—¢', 'ğ˜°', 'ğ˜–', 'ğ™¤', 
    'ğ™Š', 'ğš˜', 'ğ™¾', 'á§', 'á¬', 'Ó¨', 'Ã˜', 'á»–', 'Âº', 'Ã´', 'á»‘', 'á»“', 'á»•', 'Ãµ', 'È­', 'á¹', 'á¹', 'È«', 'Å', 'á¹‘', 'á¹“', 'Å', 'Å‘', 'á»›', 'á»', 'á»Ÿ', 'á»¡', 'á»£', 'Ç’', 'Çª', 'Ç­', 'È', 'È', 'È±', 'á»™', 'â„´', 'â’ª', 'ğ’', 'ğ—ˆ'],
    //P
    ['p', 'â´', 'â²£', 'ğ©', 'ğ‘', 'ğ’‘', 'ğ“…', 'ğ“¹', 'ğ”­', 'ğ•¡', 'ğ–•', 'ğ—‰', 'ğ—½', 'ğ˜±', 'ğ™¥', 'ğš™', 'ğ›’', 'ğœŒ', 'ğ†', 'ğ€', 'ğº', 'Î¡', 'Ğ ', 'á¢', 'á‘­', 'â„™', 'ê“‘', 'ğŠ•', 'ğ', 'ğ‘ƒ', 'ğ‘·', 'ğ’«', 'ğ“Ÿ', 'ğ–¯', 'ğ—£', 'ğ˜—', 'ğ™‹', 'ğ™¿', 
    'ğš¸', 'ğ›²', 'ğœ¬', 'ğ¦', 'ğ ', 'ï¼°', 'ğŸ‡µ', 'ğŸ…¿ï¸', 'ğ”“', 'ğ•»', 'â“Ÿ', 'á´˜', 'ğŸ„¿', 'êŸ¼', 'â‚š', 'áµ–', 'á´¾', '×§', 'á®', 'â„˜', 'Ã¾', 'â‚±', 'å©', 'á•µ', 'Æ¤', 'á¹•', 'á¹—', 'â’«'],
    //Q
    ['q', 'Ô›', 'Õ£', 'Õ¦', 'ğª', 'ğ‘', 'ğ’’', 'ğ“†', 'ğ“º', 'ğ”®', 'ğ•¢', 'ğ––', 'ğ—Š', 'ğ—¾', 'ğ˜²', 'ğ™¦', 'ğšš', 'â„š', 'âµ•', 'ğ', 'ğ‘„', 'ğ‘¸', 'ğ’¬', 'ğ“ ', 'ğ–°', 'ğ—¤', 'ğ˜˜', 'ğ™Œ', 'ğš€', 'ğŸ‡¶', 'ğ””', 'ğ•¼', 'ï½‘', 'Çª', 'ğŸ…€', 'ğŸ†€', 'ÎŒ', 'Ï™', 
    'á¤', 'ÉŠ', 'Ò¨', 'á‘«', 'á•´', 'â“†', 'â’¬'],
    //R
    ['r', 'Ğ³', 'á´¦', 'â²…', 'ê­‡', 'ê­ˆ', 'ê®', 'ğ«', 'ğ‘Ÿ', 'ğ’“', 'ğ“‡', 'ğ“»', 'ğ”¯', 'ğ•£', 'ğ–—', 'ğ—‹', 'ğ—¿', 'ğ˜³', 'ğ™§', 'ğš›', 'Æ¦', 'á¡', 'á’', 'á–‡', 'â„›', 'â„œ', 'â„', 'ê“£', 'ğ’´', 'ğŸ‡·', 'Â®ï¸', 'Ñ', 'ğ•½', 'Å˜', 'ğ“¡', 'ğ‘…', 'ï½’', 'ğŸ…', 'ğŸ†', 
    'á´š', 'É¹', 'É¿', 'áµ£', 'Ê³', 'á´¿', 'â“¡', 'å°º', 'É¾', 'ğ‘', 'ğ—¥', 'ğ˜™', 'ğ™', 'ğš', 'â±¤', 'Å•', 'Å—', 'È‘', 'È“', 'á¹™', 'á¹›', 'á¹', 'á¹Ÿ', 'â’­'],
    //S
    ['s', 'Æ½', 'Ñ•', 'êœ±', 'ê®ª', 'ğ‘ˆ', 'ï½“', 'Õ', 'á•', 'ê“¢', 'ğŠ–', 'Ê‚', 'ğŸ‡¸', '5', '5ï¸âƒ£', 'ğŸ’²', 'ğ”°', 'ğ”–', 'ğ–˜', 'ğ•¾', 'ÅŸ', 'ğ“¢', 'ğ“¼', 'ğ“ˆ', 'ğ’®', 'ğ•¤', 'ğ•Š', 'ğŸ…‚', 'ğŸ†‚', 'ê™„', 'â‚›', 'Ë¢', 'â“¢', 'à¸£', 'ğ¬', 'ğ’', 'ğ˜€', 'ğ—¦', 'ğ˜´', 
    'ğ˜š', 'ğ™¨', 'ğ™', 'ğšœ', 'ğš‚', 'Ö†', 'ä¸‚', 'á¦', 'Æ§', 'Â§', 'â‚´', 'á”•', 'Åœ', 'Å›', 'á¹¥', 'Å¡', 'á¹§', 'È™', 'á¹¡', 'á¹£', 'á¹©', 'â’®', 'ğ‘ ', 'ğ’”', 'ğ—Œ'],
    //T
    ['t', 'ğ­', 'ğ‘¡', 'ğ’•', 'ğ“‰', 'ğ“½', 'ğ”±', 'ğ•¥', 'ğ–™', 'ğ—', 'ğ˜', 'ğ˜µ', 'ğ™©', 'ğš', 'Î¤', 'á¢', 'âŠ¤', 'âŸ™', 'â²¦', 'ê“”', 'ğŠ—', 'ğŠ±', 'ğŒ•', 'ğŸ‡¹', 'Ñ‚', 'ğ”—', 'ğ•¿', 'Å¦', 'ğ“£', 'ğ’¯', 'ğ•‹', 'ï½”', 'á´›', 'ğŸ…ƒ', 'ğŸ†ƒ', 'âŠ¥', 'Ê‡', 'Æš', 'â‚œ', 'áµ—', 
    'áµ€', 'â“£', 'Õ‡', 'ğ“', 'ğ—§', 'ğ˜›', 'ğ™', 'ğšƒ', 'ã„’', 'Õ§', 'Í²', 'È¶', 'É¬', 'Æ¬', 'â€ ', 'â‚®', 'á–¶', 'Å¤', 'ä¸…', 'Å£', 'È›', 'á¹«', 'á¹­', 'á¹¯', 'á¹±', 'áº—', 'â’¯'],
    //U
    ['u', 'Ê‹', 'á´œ', 'ê­', 'ê­’', 'ğ“¶', 'áˆ€', 'á‘Œ', 'âˆª', 'â‹ƒ', 'ê“´', 'Ï…', 'Õ½', 'Ã¼', 'Ãº', 'Ã¹', 'ğŸ‡º', 'Ñ†', 'ğ”²', 'ğ”˜', 'ğ–š', 'ğ–€', 'ï¼µ', 'ğ”', 'ğ“¾', 'ğ“¤', 'ğ“Š', 'ğ’°', 'ğ•¦', 'ğ•Œ', 'ğŸ…„', 'ğŸ†„', 'âˆ©', 'áµ¤', 'áµ˜', 'áµ', 'â“¤', 'à¸¢', 
    'ğ®', 'ğ˜‚', 'ğ—¨', 'ğ˜¶', 'ğ˜œ', 'ğ™ª', 'ğ™', 'ğš', 'ğš„', 'ÊŠ', 'ã²', 'Å³', 'à¸™', 'ã„©', 'Õ´', 'É„', 'Õ¾', 'á‘˜', 'Ç—', 'Ã»', 'Ç–', 'Çš', 'Çœ', 'Å©', 'Å«', 'Å­', 'Å¯', 'Å±', 'Æ°', 'Ç”', 'á¹¹', 'á¹»', 'á»©', 'á»«', 'á»­', 'á»¯', 'á»±', 'È•', 'È—', 
    'á¹³', 'á¹µ', 'á¹·', 'á»¥', 'á»§', 'â’°', 'ğ‘¢', 'ğ’–', 'ğ—'],
    //V
    ['v', 'Î½', 'Ñµ', 'á´ ', 'â…´', 'âˆ¨', 'â‹', 'ê®©', 'á¯', 'â´¸', 'ê“¦', 'ğŸ‡»', 'ğ”³', 'ğ”™', 'ğ–›', 'ğ–', 'ğ•§', 'ğ“¿', 'ğ“¥', 'ğ“‹', 'ğ’±', 'ğ•', 'ï½–', 'ğŸ†…', 'Î›', 'ÊŒ', 'áµ¥', 'áµ›', 'â±½', 'â“¥', '×©', 'ğ¯', 'ğ•', 'ğ˜ƒ', 'ğ—©', 'ğ˜·', 'ğ˜', 'ğ™«', 
    'ğ™‘', 'ğšŸ', 'ğš…', 'á‰', 'Û·', 'à¸‡', 'âˆš', 'áº', 'Ñ¶', 'á¹½', 'á¹¿', 'â’±', 'ğ‘£', 'ğ’—', 'ğ—'],
    //W
    ['w', 'É¯', 'Ñ¡', 'Ô', 'Õ¡', 'á´¡', 'ê®ƒ', 'á”', 'ê“ª', 'ğŸ‡¼', 'Ñˆ', 'Ñ‰', 'ğ”´', 'ğ”š', 'ğ–œ', 'ğ–‚', 'Å´', 'ï¼·', 'ğ”€', 'ğ“¦', 'ğ“Œ', 'ğ’²', 'ğ•¨', 'ğ•', 'ğŸ…†', 'ğŸ††', 'Ê', 'Ê·', 'áµ‚', 'â“¦', 'à¸¬', 'ğ°', 'ğ–', 'ğ˜„', 'ğ—ª', 'ğ˜¸', 
    'ğ˜', 'ğ™¬', 'ğ™’', 'ğš ', 'ğš†', 'á‡', 'á¿³', 'àºŸ', 'Ï‰', 'â‚©', 'å±±', 'à°š', 'á—¯', 'á˜º', 'áº', 'áºƒ', 'áº…', 'áº‡', 'áº‰', 'áº˜', 'â’²', 'ğ‘¤', 'ğ’˜', 'ğ—'],
    //X
    ['x', 'Ã—', 'Ñ…', 'á•', 'á•½', 'á™®', 'â…¹', 'â¤«', 'â¤¬', 'â¨¯', 'ğ±', 'ğ‘¥', 'ğ’™', 'ğ“', 'ğ”', 'ğ”µ', 'ğ•©', 'ğ–', 'ğ—‘', 'ğ˜…', 'ğ˜¹', 'ğ™­', 'ğš¡', 'ï½˜', 'Î§', 'á™­', 'áš·', 'â•³', 'â²¬', 'âµ', 'ê“«', 'ê³', 'ğŠ', 'ğŠ´', 'ğŒ—', 'ğŒ¢', 'Ò³', 'ğŸ‡½', 
    'âŒ', 'â', 'âœ–ï¸', 'ğ”›', 'ğ–ƒ', 'ğ—', 'ğ“§', 'ğ’³', 'ä¹‚', 'ğ•', 'ğŸ…‡', 'ğŸ†‡', 'áƒ¯', 'â‚“', 'Ë£', 'â“§', '×', 'ğ—«', 'ğ˜Ÿ', 'ğ™“', 'ğš‡', 'Ó¼', 'Ó¾', 'ï¾’', 'áº‹', 'áº', 'â’³'],
    //Y
    ['y', 'É£', 'Ê', 'Î³', 'Ñƒ', 'Ò¯', 'áƒ§', 'á¶Œ', 'á»¿', 'â„½', 'ê­š', 'Î¥', 'Ï’', 'á©', 'á½', 'â²¨', 'ê“¬', 'ğŠ²', 'Ã½', 'ğŸ‡¾', 'ğ”¶', 'ğ”œ', 'ğ–', 'ğ–„', 'Â¥', 'ğ“', 'ğ”‚', 'ğ“¨', 'ğ’´', 'ğ•ª', 'ğ•', 'ï½™', 'ğŸ…ˆ', 'ğŸ†ˆ', 'â…„', 'Ê', 'Ê¸', 'â“¨', 
    '×¥', 'ğ²', 'ğ˜', 'ğ˜†', 'ğ—¬', 'ã„š', 'ğ˜º', 'ğ˜ ', 'ğ™®',' ğ™”', 'ğš¢', 'ğšˆ', 'à¸¯', 'É', 'ï¾˜', 'Ó‹', 'á–»', 'Ñ‡', 'Æ³', 'Ğ', 'Ã¿', 'Å·', 'È³', 'áº', 'áº™', 'á»³', 'á»µ', 'á»·', 'á»¹', 'â’´', 'ğ‘¦', 'ğ’š', 'ğ—’'],
    //Z
    ['z', 'á´¢', 'ê®“', 'Î–', 'â„¤', 'ê“œ', 'ï¼º', 'Ê', 'Å¼', 'ğŸ‡¿', 'ğ–Ÿ', 'ğ–…', 'â“©', 'Å¾', 'ğ”ƒ', 'ğ“©', 'ğ“', 'ğ’µ', 'ğ•«', 'ğŸ…‰', 'ğŸ†‰', 'Æ¸', 'á¶»', 'Õ¹', 'È¥', 'ğ³', 'ğ™', 'ğ˜‡', 'ğ—­', 'ğ˜»', 'ğ˜¡', 'ğ™¯', 'ğ™•', 'ğš£', 'ğš‰', 'Ê‘', 'â±«', 'ä¹™', 
    'É€', 'á˜”', 'Æµ', 'Åº', 'áº‘', 'áº“', 'áº•', 'â’µ', 'ğ‘§', 'ğ’›', 'ğ”·', 'ğ—“']
];

/**
 * Finds all blacklist table entries and regenerates blacklist_regexp
 */
function generateBlacklist() {
    blacklist
        .findAll()
        .then(entries => {
            const regexp_source = entries
                .map(e => e.word
                    .toLowerCase()
                    .replace(
                        /\[\^?([-A-Za-z]+?)\]|([A-Za-z])/g, 
                        (match, set, single) => {
                            //set is like '[abc]'
                            //single is just 'a'

                            //convert range set to full set
                            //ex: [a-d] => [abcd]
                            set = set ? set.replace(/([A-Za-z])-([A-Za-z])/g, (match, range_start, range_end) => {
                                let range_all = '';
                                const first_code = range_start.charCodeAt(0);
                                const last_code = range_end.charCodeAt(0);
                                for (let i = first_code; i <= last_code; i++) range_all += String.fromCharCode(i);
                                return range_all;
                            }) : null;

                            //finds confusables and spreads them into array or just returns the char itself
                            const chars = [...(set ?? single)].flatMap(char => confusables.find(set => set[0] === char) ?? char);

                            //converting to set and spreading into new array removes duplicates
                            return `(?:${[...new Set(chars)].join('|')})`;
                        }
                    )
                )
                .join('|');

            blacklist_regexp = new RegExp(regexp_source, 'ig');
            console.log(blacklist_regexp);
        })
        .catch(console.error);
}

/**
 * @returns cached blacklist regular expression
 */
function getBlacklist() {
    return blacklist_regexp;
}

//arrays of cached ids
let whitelisted_users = [];
let whitelisted_channels = [];
let whitelisted_roles = [];

/**
 * Finds all whitelist table entries and filters them into corresponding caches
 */
function generateWhitelists() {
    whitelist
        .findAll()
        .then(entries => {
            whitelisted_users = [];
            whitelisted_roles = [];
            whitelisted_channels = [];

            entries.forEach(entry => {
                switch (entry.type) {
                    case '@':
                        whitelisted_users.push(entry.id);
                        break;
                    case '@&':
                        whitelisted_roles.push(entry.id);
                        break;
                    case '#':
                        whitelisted_channels.push(entry.id);
                }
            });
        })
        .catch(console.error);
}

/**
 * @param {Message}
 * @returns True if message meets whitelist criteria
 */
function checkWhitelists(message) {
    return whitelisted_users?.includes(message.author.id) 
        || whitelisted_channels?.includes(message.channelId) 
        || message.member?.roles.cache.some(role => whitelisted_roles?.includes(role.id) );
}

/**
 * @param {TextChannel} channel
 * @returns {Promise<Webhook>} Fetched or newly created GudBot-owned webhook
 */
async function fetchOrCreateHook(channel) {
    //first check local cache
    let hook = webhooks_cache.get(channel.id);
    if (hook) return hook;

    //then fetch and check channel's existing webhooks
    const channel_hooks = await channel.fetchWebhooks().catch(console.error);
    hook = channel_hooks?.find(hook => hook.owner.id === ids.client);
    if (hook) {
        //cache it
        webhooks_cache.set(channel.id, hook);
        return hook;
    }

    //if it doesn't exist, create and cache it
    hook = await channel.createWebhook('GudBot').catch(console.error);
    if (hook) {
        webhooks_cache.set(channel.id, hook);
        return hook;
    }
    
    //couldnt fetch or create
    return null;
}

/**
 * @param {string} content 
 * @returns {string|null} Censored message content or null if censorship was unnecessary
 */
function parseContent(content) {
    const time1 = new Date().getTime();

    let modified = false;

    /**
     * Strings that have to be reinserted after censorship
     * @type {{ str: string; is_splitter: boolean; reinsert_idx: number; lookup_idx: number; }[]}
     */
    let reinsertions = [];

    //the sum of all saved reinsertions' string's length
    let reinsert_length = 0;

    //the sum of all discarded zero-width string's length
    let discarded_length = 0;

    //remove and later reinsert
    //custom emojis:    <:\w{2,32}:[0-9]{17,19}>
    //urls:             https?:\/\/\w{2}\S+
    //whitespace:       \s+
    //formatters:       [*~`|]+
    //special chars:    [!@#$%^&()\-_+={}\[\]\\/:;'"<>,.?â€¦â€šâ€Ë†â€¹â€ºâ€˜â€™â€œâ€â€¢â€“â€”Ëœâ„¢Â¦Â¨Â«Â¬Â¯Â´Â·Â¸Â»Â¿]+
    //
    //remove and do NOT reinsert
    //zero-width chars: [\u200b-\u200f\u2060-\u2064\u206a-\u206f\u17b4-\u17b5\u00ad\u034f\u061c\u180e]+
    content = content.replace(
        /(<:\w{2,32}:[0-9]{17,19}>)|(https?:\/\/\w{2}\S+)|(\s+)|([*~`|]+)|([\u0021-\u0029\u002b-\u002f\u003a-\u0040\u005b-\u005f\u007b\u007d\u00a6\u00a8\u00ab\u00ac\u00af\u00b4\u00b7\u00b8\u00bb\u00bf\u02c6\u02dc\u2013\u2014\u2018\u2019\u201a\u201c\u201d\u201e\u2022\u2026\u2039\u203a\u2122]+)|[\u200b-\u200f\u2060-\u2064\u206a-\u206f\u17b4-\u17b5\u00ad\u034f\u061c\u180e]+/g, 
        (match, emoji, url, spaces, formatters, special, index) => {
            //save everything but zero width chars for reinsertion later
            if (emoji ?? url ?? spaces ?? formatters ?? special) {
                const idx = index - discarded_length;
                reinsertions.push({
                    str: match,
                    is_splitter: !!(spaces || special),
                    reinsert_idx: idx,
                    lookup_idx: idx - reinsert_length
                });
                //keep track of how many reinsertions were removed (total char length), so that we could look up their would-be indexes in the 'clean' string
                reinsert_length += match.length;
            }
            //zero width characters will be discarded, so we have to keep track of how many chars were removed to adjust reinsertion indexes
            else discarded_length += match.length;

            //remove
            return '';
        }
    );

    //replace blacklisted words with stars
    let censored = content.replace(blacklist_regexp, (word, index) => {
        //check if word begins with repeating letter (ex: tttest)
        const repeating_prefix = index + word.search(/^([A-Za-z])\1+/);
        //check if word ends on repeating letter (ex: testsss)
        const repeating_suffix = index + word.search(/([A-Za-z])\1+$/);

        //will be prepended to censored word at the end if necessary
        let prefix = '';
        //will be appended to censored word at the end if necessary
        let suffix = '';

        //if not found, repeating idx will be index - 1, hence the >=
        let look_for_prefix = repeating_prefix >= index;
        let look_for_suffix = repeating_suffix >= index;

        if (look_for_prefix || look_for_suffix) {
            //index of first char after word
            const end_index = index + word.length;

            //look for repeating prefix before this index
            const repeating_prefix_end = look_for_suffix ? repeating_suffix : end_index;

            //find last reinsertion within either repeating pattern
            for (let i = reinsertions.length - 1; i >= 0; i--) {
                const { str, lookup_idx } = reinsertions[i];

                //check repeating suffix pattern
                if (look_for_suffix && lookup_idx >= repeating_suffix && lookup_idx < end_index) {
                    //split off everything that comes after reinsertion
                    suffix = str + word.substring(lookup_idx - index);
                    word = word.substring(0, lookup_idx - index);

                    //delete reinsertion
                    reinsertions.splice(i, 1);
                    
                    //suffix found
                    look_for_suffix = false;
                }
                //check repeating prefix pattern
                else if (look_for_prefix && lookup_idx >= repeating_prefix && lookup_idx < repeating_prefix_end) {
                    //split off everything that comes before reinsertion
                    prefix = word.substring(0, lookup_idx - index) + str;
                    word = word.substring(lookup_idx - index);

                    //delete reinsertion
                    reinsertions.splice(i, 1);

                    //prefix found
                    look_for_prefix = false;
                }

                //do not continue searching if both found (or didnt need to be found in the first place)
                if (!look_for_prefix && !look_for_suffix) break;
            }
        }

        //spread word into array of chars
        let chars = [...word];

        //replace every char after the first with stars
        for (let i = 1; i < chars.length; i++) { 
            chars[i] = 'â‹†'; // '\\*'
        }

        //join censored chars together
        const censored_word = chars.join('');

        //if word consisted of surrogative pairs, it will be shorter after censorship
        const length_diff = word.length - censored_word.length;

        //if length_diff != 0
        if (length_diff) {
            //index of first char after word (may have changed, which is why I don't use the previous one)
            const end_index = index + word.length;

            //adjust reinsertion indexes of strings that come after word
            reinsertions = reinsertions.map(e => {
                if (e.lookup_idx >= end_index) e.reinsert_idx -= length_diff;
                return e;
            });
        }

        //note that censorship was done
        modified = true;

        //replace uncensored word
        return prefix + censored_word + suffix;
    });

    //if content was not modified, meaning no censorship was necessary => do not proceed further
    if (!modified) return null;

    //reinsert previously removed strings
    discarded_length = 0;
    reinsertions.forEach(e => {
        const { str, is_splitter, reinsert_idx } = e;

        //adjust index based on how many prior chars were discarded
        const index = reinsert_idx - discarded_length;

        //do not reinsert splitters (spaces or special chars) if next char is a star, but keep track of how many splitters were discarded
        if (is_splitter && censored[index] === 'â‹†')
            discarded_length += str.length;
        //reinsert
        else censored = censored.substring(0, index) + str + censored.substring(index);
    });

    const time2 = new Date().getTime();
    console.log(`censoring: ${time2-time1}ms`);

    //return the successfully censored content
    return censored;
}

/**
 * Detects blacklisted words in message content, censors them and resends the message with a webhook so as to mimic original author's name and avatar.
 * @param {Message} message 
 * @returns {Promise<boolean>} Whether or not message was censored.
 */
async function censorMessage(message) {
    //only check messages in server
    if (message.channel.guildId !== ids.guild) return;

    //threads dont have webhooks, so in that case we get the parent channel
    const is_thread = message.channel.isThread();
    const channel = is_thread ? message.channel.parent : message.channel;

    //fetch/create channel webhook if it's not in cache
    //we do this on every messageCreate, not just the ones that need to be censored, so as to populate the cache
    const fetch_hook = fetchOrCreateHook(channel).catch(console.error);

    //don't do anything if content is empty
    if (!message.content) return false;

    //don't do anything if regexp is empty
    if (blacklist_regexp.source === '(?:)') return false;

    //dont censor message if sent in whitelisted channel or by whitelisted user
    if (checkWhitelists(message)) return false;

    //find blacklisted words in message content and censor if necessary
    let censored = parseContent(message.content);

    //if no blacklisted words found, do not proceed further
    if (!censored) return false;

    //prepend fake reply to beginning of censored message content
    if (message.type === 'REPLY') {
        //catch exception if reply isnt found (non critical error)
        const replied_msg = await message.fetchReference().catch(e => logUnless(e, ids.errors.unknown_message));
        censored = prependFakeReply(censored, replied_msg);
    }

    //split message if it's too big
    let censored_followup;

    const max_length = 2000; // - star_count;
    if (censored.length > max_length) {

        const cutoff_index = findLastSpaceIndex(censored, max_length);
        censored_followup = censored.substring( cutoff_index );

        //if cutoff point was a newline, add fake bold ** ** to preserve it in the beginning of the followup message
        if (censored_followup.startsWith('\n')) 
            censored_followup = `** **${censored_followup}`
        
        censored = censored.substring(0, cutoff_index);
    }

    //mimic original author's name and pfp
    //mentions are disabled because we dont want to ping people twice
    let message_options = {
        content: censored,
        username: message.member.displayName,
        avatarURL: message.member.displayAvatarURL(),
        allowedMentions: { parse: [] },
        threadId: is_thread ? message.channelId : null
    };

    //check if original message had attachments and filter out ones that are above the current guild's upload size limit
    const attachments = [...message.attachments?.filter(file => file.size <= getGuildUploadLimit(message.guild) ).values()];
    //add the attachments to the message if there will be no followup (we dont want the attachments to between the intial and followup message)
    if (!censored_followup && attachments.length > 0) message_options.files = attachments;

    //delete user's original uncensored message
    message.delete().catch(e => logUnless(e, ids.errors.unknown_message));
    console.log('deleting uncensored');

    //await for fetch_hook resolve
    const hook = await fetch_hook;
    if (!hook) return false;

    const send = [];
    send.push(
        //send censored message through webhook
        hook.send(message_options)
            //then cache message id and corresponding author id, so that we could check this for the jail context menu command
            .then(new_message => {
                cacheAuthorId(new_message.id, message.author.id);
                
                //check newly censored message for spam
                let hybrid_message = new_message;
                hybrid_message.author = message.author;
                hybrid_message.member = message.member;
                addToMessageGroups(hybrid_message).catch(console.error);
            })
    );
    
    //this is part 2 of large messages
    if (censored_followup) {
        //reuse the same MessageOptions, just change the text content
        message_options.content = censored_followup;
        //if attachments were not sent with first message
        if (attachments.length > 0) message_options.files = attachments;
        
        send.push(
            //send censored message through webhook
            hook.send(message_options)
                //then cache message id and corresponding author id, so that we could check this for the jail context menu command
                .then(new_message => cacheAuthorId(new_message.id, message.author.id))
        );
    }

    console.log('sending censored');
    //await both messages to be sent
    const has_sent = await Promise.all(send);

    return has_sent;
}

module.exports = {
    censored_authors_cache,
    generateBlacklist,
    getBlacklist,
    generateWhitelists,
    checkWhitelists,
    censorMessage
};